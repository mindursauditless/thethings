## 2. **Module 1: Indexing & Crawling**

```markdown
<!-- Filename: module1-indexing-crawling.md -->

# Module 1: Indexing & Crawling

## Purpose
Ensure all important pages (services, locations, etc.) are crawlable, indexable, and returning 200 status codes. Catch and prevent foundational issues that block visibility.

## Inputs Required
- Sitemap presence and structure
- Robots.txt contents
- Meta robots tags
- HTTP response codes (200/301/404/500/etc.)
- site: search sampling (homepage, services, locations)

## Philosophy
- Indexing is foundational: if Google canâ€™t see it, nothing else matters.
- Donâ€™t optimize SEO content or fix other modules until crawl/index issues are fixed.
- Not every page needs to be indexedâ€”evaluate value first.
- Show data: Donâ€™t just say a page is missing; show why it matters.

## Core Checks

| Check                                   | Method               | Output                                                             |
|-----------------------------------------|----------------------|--------------------------------------------------------------------|
| Sitemap present & includes priority     | Parse XML            | Missing sitemap or incomplete coverage                             |
| robots.txt blocking key paths           | Crawl robots.txt     | Flag disallowed service/location paths                             |
| Noindex on important pages              | Scan head/meta       | Flag meta noindex or x-robots header                               |
| Core pages not indexed                  | Google site: search  | List missing service/location/home pages                           |
| Pages returning 404 or 500             | Response headers     | Flag non-200 on critical pages                                     |
| Redirects to homepage                  | Track redirect chain | Flag if location/service pages redirect to homepage                |
| Orphaned critical pages                | Compare internal links| Flag pages w/ 0 incoming links that should be indexed              |

## OS Tone
- â€œFix this or nothing else matters.â€
- â€œYouâ€™re optimizing a page Google doesnâ€™t see.â€

## Decision Context
- Only flag non-indexed pages if theyâ€™re critical (revenue, nav, GBP-ref).
- If borderline, use ğŸ” Validate.

## MAL Crossover
- **Internal Linking**: Orphaned pages â†’ add contextual links.
- **IA**: Key pages missing from nav â†’ might remove from index or merge.

## Example Findings
- **Finding**: Homepage 200 but doesnâ€™t appear in `site:domain.com`.
  - **Response**: ğŸ§± Foundation, ğŸ“Œ Must Act â†’ â€œRed flag for trust/crawl. Check canonical, internal links, sitemap coverage.â€
- **Finding**: 8/10 location pages 200 but unindexed, no backlinks, no internal links.
  - **Response**: ğŸ§± Foundation, ğŸ’¥ High Impact, â“ Blind Spot â†’ â€œStructurally invisible. Consolidate or fix.â€

## Recommendation Tags
- ğŸ§± Foundation
- ğŸ“Œ Must Act
- ğŸ’¥ High Impact
- ğŸ” Validate
- â“ Blind Spot
- ğŸ“ Nice to Know

## Execution Risk Notes
- Donâ€™t recommend indexing everything blindly.
- If deleting unindexed pages, confirm why they failed.
- Watch for redirect chains/homepage redirectsâ€”trust killers.
- Donâ€™t just say â€œadd to sitemapâ€â€”ask why it wasnâ€™t there first.

## Future Enhancements
- GSC integration
- Visual crawl depth map
- Compare sitemap, nav, internal links
- Bulk validation vs. GBP-linked URLs
